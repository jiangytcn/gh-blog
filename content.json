{"pages":[{"title":"about","text":"- 2012年工作，一直从事云计算开发，掌握web开发流程，熟悉网络开发; - 专业知识扎实，具备自学、独立分析、解决问题的能力，良好的团队合作意识; - 英语六级，熟练阅读和理解外文技术书籍，掌握常用的算法与数据结构; - 有4年的linux系统使用经验，熟练使用常用系统命令，使用 vim编辑器; - 掌握Linux下Java(MVC spring struts)、Python(paste route django wsgi)等后台开发语言，以及Html、JSP、Javascript、Css等前台知识; - 熟练使用Mysql、MongoDB等数据库,CI工具，Git jemkins gerrit; - 熟悉Kvm、Xenserver、Exi,Libvirt、Openstack、Cloudstack等相关虚拟化知识; What i did 201311-至今 某跨国公司 PaaS cloudfoundry 系统研发 基于Cloudstack 完成智慧城市私有云的建设主要负责CS各模块的稳定运行，根据功能需求，添加plugin 熟练掌握ACS各模块原理，Maven 项目管理，可进行二次开发 201206-201311 北京某科技有限公司 该公司主要发展方向是，基于Openstack为企业提供开源云计算解决方案该项目现为北京最大的民营IDC提供公有云解决方案，线上成功部署虚拟机近千台任职期间，主要参与开发设计上层用户自服务云计算管理平台，包括前台页面展示、后台数据处理、计费和后期的系统优化及部分运维工作 根据公司前期制定的计划，在经过4个月的时间内，主要在LINUX 平台中使用的Spring，struts 框架， 以RESTAPI 来与底层的openstack 各个服务通信，完成更自服务平台的开发设计，包括监控、LbaaS功能的完成","link":"/about/index.html"}],"posts":[{"title":"Setting Debug Environment Of Cloudstack In Production","text":"This introduction will outline specifically how setting debug environment in production of Cloudstack, and how building a single project into a patch. Configure Tomcat$ vim /usr/sbin/tomcat6 Adding -server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8787 into the file above 35 -Djava.io.tmpdir=\"$CATALINA_TMPDIR\" \\ 36 -Djava.util.logging.config.file=\"${CATALINA_BASE}/conf/logging.properties\" \\ 37 -Djava.util.logging.manager=\"org.apache.juli.ClassLoaderLogManager\" \\ 38 -server -Xdebug -Xnoagent -Djava.compiler=NONE -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8787 \\ Now configure you eclipse to the server, go Debugging. Building Single Project Some reasons you modified a project, for instance cloud-server, and you want your new code to be taken into effect, you should build a new jar file, and then applying the patch.cd ~/cloudstack4.1.0 mvn clean mvn -pl :cloud-server After a while when you saw something like below, then you got a new patch. ------------------------------------------------------------------------ BUILD SUCCESS ------------------------------------------------------------------------ Total time: 3:01.915s Finished at: Wed Feb 12 14:56:24 CST 2014 Final Memory: 26M/233M And replace the old cloud-server-4.1.0.jar with new one , restart cloudstack-management, go hacking.","link":"/2019/07/19/2014-02-12-setting-debug-environment-of-cloudstack-in-production/"},{"title":"Setting Django oscar Environment","text":"PSQL Settings bash-4.1$ psql createdb -T template_postgis oscar oscar=# \\d List of relations Schema | Name | Type | Owner --------+-------------------+-------+---------- public | geography_columns | view | postgres public | geometry_columns | table | postgres public | spatial_ref_sys | table | postgres (3 rows) Solr Settingscd ***/solr-4.6.1/example/solr cp -rf example oscar cp -f sites/demo/deploy/solr/schema.xml oscar/conf cd .. java -jar start.jar Browser http://ip:8983/solr finding your app oscar Django-oscar demo settingscd ***/django-oscar/sites/demo vim settings.py update sor connections 271 HAYSTACK_CONNECTIONS = { 272 'default': { 273 'ENGINE': 'haystack.backends.solr_backend.SolrEngine', 274 'URL': 'http://127.0.0.1:8983/solr/oscar', 275 }, 276 } cd dir/django-oscar make demoAfter a while everyting ok,cd - and runpython manage.py runserver 0.0.0.0:8000 Browser ip:8000","link":"/2019/07/19/2014-02-14-setting-django-oscar-environment/"},{"title":"Cloudstack 4.2.1 User Guide","text":"Adding nic to a vm Be sure that the network to be added had a VR running The network doesn’t add before Shutdown VMClick INSTANCES -->> VM -->> Details -->> NICS -->> Add network to VM -->> select network -->> OK","link":"/2019/07/19/2014-02-18-cloudstack-421-user-guide/"},{"title":"Django oscar I18N","text":"Translating OscarWithin your project, create a locale folder and a symlink to Oscar so that ./manage.py makemessages finds Oscar’s translatable strings: mkdir locale i18n ln -s $PATH_TO_OSCAR i18n/oscar ./manage.py makemessages --symlinks --locale=zh_CN Now the i18n files are under local directory,edit django.po filesand run command to generate django.mo file. ./manage.py compilemessages --locale=zh_CN Restart your django server, vist your website to verify.","link":"/2019/07/19/2014-02-26-django-oscar-i18n/"},{"title":"host cpu comprehension","text":"Linux 物理机 查看Linux系统中物理与逻辑cpu的相关信息 Linux 下/proc/cpuinfo文件会显示cpu的信息 逻辑CPU个数是指cat /proc/cpuinfo 所显示的processor的个数 cat /proc/cpuinfo | grep “processor” | wc -l 物理CPU个数，是指physical id（的值）的数量 cat /proc/cpuinfo | grep “physical id” | sort | uniq | wc -l 每个物理CPU中Core的个数：每个相同的physical id都有其对应的core id。如core id分别为1、2、3、4，则表示是Quad-Core CPU，若core id分别是1、2，则表示是Dual-Core。 cat /proc/cpuinfo | grep “cpu cores” | wc -l 逻辑CPU：每个物理CPU中逻辑CPU(可能是core, threads或both)的个数： cat /proc/cpuinfo | grep “siblings” 它既可能是cores的个数，也可能是core的倍数。当它和core的个数相等时，表示每一个core就是一个逻辑CPU，若它时core的2倍时，表示每个core又enable了超线程（Hyper-Thread）。 比如：一个双核的启用了超线程的物理cpu，其core id分别为1、2，但是sibling是4，也就是如果有两个逻辑CPU具有相同的”core id”，那么超线程是打开的。 XenserverXenServer中Socket、Core、以及超线程后的核心之间在XenServer中CPU的排序关系","link":"/2019/07/19/2014-03-20-host-cpu-comprehension/"},{"title":"Cloudstack 4.2.1 Spawn VM Workflow","text":"","link":"/2019/07/19/2014-04-18-cloudstack-421-spawn-vm-workflow/"},{"title":"Python RE 正则表达式","text":"####简单介绍正则表达式并不是Python的一部分。正则表达式是用于处理字符串的强大工具，拥有自己独特的语法以及一个独立的处理引擎，效率上可能不如str自带的方法，但功能十分强大。得益于这一点，在提供了正则表达式的语言里，正则表达式的语法都是一样的，区别只在于不同的编程语言实现支持的语法数量不同；但不用担心，不被支持的语法通常是不常用的部分。如果已经在其他语言里使用过正则表达式，只需要简单看一看就可以上手了。下图展示了使用正则表达式进行匹配的流程： 正则表达式的大致匹配过程是：依次拿出表达式和文本中的字符比较，如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。如果表达式中有量词或边界，这个过程会稍微有一些不同，但也是很好理解的，看下图中的示例以及自己多使用几次就能明白。 下图列出了Python支持的正则表达式元字符和语法 ####数量词的贪婪模式与非贪婪模式正则表达式通常用于在文本中查找匹配的字符串。Python里数量词默认是贪婪的（在少数语言里也可能是默认非贪婪），总是尝试匹配尽可能多的字符；非贪婪的则相反，总是尝试匹配尽可能少的字符。例如：正则表达式”ab*“ 如果用于查找”abbbc”，将找到”abbb”。而如果使用非贪婪的数量词 “ab*?”，将找到”a”。 ####反斜杠的困扰与大多数编程语言相同，正则表达式里使用”&quot;作为转义字符，这就可能造成反斜杠困扰。假如你需要匹配文本中的字符”&quot;，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\\\“：前两个和后两个分别用于在编程语言里转义成反斜杠，转换成两个反斜杠后再在正则表达式里转义成一个反斜杠。Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\\“表示。同样，匹配一个数字的”\\d”可以写成r”\\d”。有了原生字符串，你再也不用担心是不是漏写了反斜杠，写出来的表达式也更直观。 ####匹配模式正则表达式提供了一些可用的匹配模式，比如忽略大小写、多行匹配等，这部分内容将在Pattern类的工厂方法re.compile()中一起介绍。 ###RE 模块 ####开始使用rePython通过re模块提供对正则表达式的支持。使用re的一般步骤是先将正则表达式的字符串形式编译为Pattern实例，然后使用Pattern实例处理文本并获得匹配结果（一个Match实例），最后使用Match实例获得信息，进行其他的操作。 import re # 将正则表达式编译成Pattern对象 pattern = re.compile(r'hello') # 使用Pattern匹配文本，获得匹配结果，无法匹配时将返回None match = pattern.match('hello world!') if match: print match.group() ### 输出 ### # hello re.compile(strPattern [, flag]): 这个方法是Pattern类的工厂方法，用于将字符串形式的正则表达式编译为Pattern对象。 第二个参数flag是匹配模式，取值可以使用按位或运算符’|’表示同时生效，比如re.I | re.M。另外，你也可以在regex字符串中指定模式，比如re.compile(‘pattern’, re.I | re.M)与re.compile(‘(?im)pattern’)是等价的。可选值有： * re.I(re.IGNORECASE): 忽略大小写（括号内是完整写法，下同） * M(MULTILINE): 多行模式，改变&apos;^&apos;和&apos;$&apos;的行为（参见上图） * S(DOTALL): 点任意匹配模式，改变&apos;.&apos;的行为 * L(LOCALE): 使预定字符类 \\w \\W \\b \\B \\s \\S 取决于当前区域设定 * U(UNICODE): 使预定字符类 \\w \\W \\b \\B \\s \\S \\d \\D 取决于unicode定义的字符属性 * X(VERBOSE):详细模式。这个模式下正则表达式可以是多行，忽略空白字符，并可以加入注释。以下两个正则表达式是等价的a = re.compile(r\"\"\" \\d + # the integral part \\. # the decimal point \\d * # some fractional digits\"\"\", re.X) b = re.compile(r\"\\d+\\.\\d*\") re提供了众多模块方法用于完成正则表达式的功能。这些方法可以使用Pattern实例的相应方法替代，唯一的好处是少写一行re.compile()代码，但同时也无法复用编译后的Pattern对象。这些方法将在Pattern类的实例方法部分一起介绍。如上面这个例子可以简写为 m = re.match(r'hello', 'hello world!') print m.group()","link":"/2019/07/19/2014-05-15-python-re/"},{"title":"OpenStack Nova 使用SQLAlchemy 操作Flavor(Mysql backend)","text":"##SQLAlchemy 简介 The SQLAlchemy Object Relational Mapper presents a method of associating user-defined Python classes with database tables, and instances of those classes (objects) with rows in their corresponding tables. It includes a system that transparently synchronizes all changes in state between objects and their related rows, called a unit of work, as well as a system for expressing database queries in terms of the user defined classes and their defined relationships between each other. 我的理解是，SQLAlchemy 是实体/关系映射的一种操作数据的方式， 实体是由Python所编写的类， 这个类的每一个实体，就对应于数据库中的每一条元组（行数据）。其中对这个类的实体的操作，直接映射（影响）到数据库中对应的元组， 这种方式叫做 工作单元（操作单元，有点类似于一个原子操作） 自己写的查询Flavor例子 1 from sqlalchemy.orm import sessionmaker 2 from sqlalchemy import create_engine 3 from sqlalchemy.ext.declarative import declarative_base 4 from sqlalchemy import Column, Integer, String, Float, Boolean 5 6 sql_connection = \"mysql://root:root@localhost/nova?charset=utf8\" 7 engine = create_engine(sql_connection, echo=True) #echo=True 设置该项后，可以打印出sql的执行过程 8 Session = sessionmaker(bind=engine) 9 session = Session() 10 11 class NovaBase(): 12 pass 13 14 BASE = declarative_base() # 用户创建与DB映射的基类 15 16 class InstanceTypes(BASE, NovaBase): 17 __tablename__ = \"instance_types\" # 数据库中表的名称 18 id = Column(Integer, primary_key=True) #Column 用于定义数据表 \"instance_types”的字段， 其参数是该字段的具体的类型 19 name = Column(String(255)) 20 memory_mb = Column(Integer) 21 vcpus = Column(Integer) 22 root_gb = Column(Integer) 23 ephemeral_gb = Column(Integer) 24 flavorid = Column(String(255)) 25 swap = Column(Integer, nullable=False, default=0) 26 rxtx_factor = Column(Float, nullable=False, default=1) 27 vcpu_weight = Column(Integer, nullable=True) 28 disabled = Column(Boolean, default=False) 29 is_public = Column(Boolean, default=True) 30 31 flavors = session.query(InstanceTypes).all() #查询数据表 32 for flavor in flavors: 33 print flavor.id, flavor.name 代码输出 2013-05-15 18:41:10,928 INFO sqlalchemy.engine.base.Engine SELECT DATABASE() 2013-05-15 18:41:10,929 INFO sqlalchemy.engine.base.Engine () 2013-05-15 18:41:10,933 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'character_set%%' 2013-05-15 18:41:10,934 INFO sqlalchemy.engine.base.Engine () 2013-05-15 18:41:10,935 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'lower_case_table_names' 2013-05-15 18:41:10,936 INFO sqlalchemy.engine.base.Engine () 2013-05-15 18:41:10,937 INFO sqlalchemy.engine.base.Engine SHOW COLLATION 2013-05-15 18:41:10,937 INFO sqlalchemy.engine.base.Engine () 2013-05-15 18:41:10,946 INFO sqlalchemy.engine.base.Engine SHOW VARIABLES LIKE 'sql_mode' 2013-05-15 18:41:10,946 INFO sqlalchemy.engine.base.Engine () 2013-05-15 18:41:10,948 INFO sqlalchemy.engine.base.Engine BEGIN (implicit) 2013-05-15 18:41:10,950 INFO sqlalchemy.engine.base.Engine SELECT instance_types.id AS instance_types_id, instance_types.name AS instance_types_name, instance_types.memory_mb AS instance_types_memory_mb, instance_types.vcpus AS instance_types_vcpus, instance_types.root_gb AS instance_types_root_gb, instance_types.ephemeral_gb AS instance_types_ephemeral_gb, instance_types.flavorid AS instance_types_flavorid, instance_types.swap AS instance_types_swap, instance_types.rxtx_factor AS instance_types_rxtx_factor, instance_types.vcpu_weight AS instance_types_vcpu_weight, instance_types.disabled AS instance_types_disabled, instance_types.is_public AS instance_types_is_public FROM instance_types 2013-05-15 18:41:10,950 INFO sqlalchemy.engine.base.Engine () 1 m1.medium 2 m1.tiny 3 m1.large 4 m1.xlarge 5 m1.small 6 m1.nano 7 m1.micro ###Nova 中所对应的代码结构 nova/openstack/common/db/sqlalchemy/models.py 定义了SQLAlchemy 的基类， 所有的对数据的操作，通过该类中定义的方法来实现， 其子类，只需要调用相关的方法即可 nova/db/sqlalchemy/models.py 定义了nova数据中的所有的表,以InstanceTypes 为例 BASE = declarative_base() # 与上一个类子中的方法一样 class NovaBase(models.SoftDeleteMixin, models.ModelBase): #区别在这里， models 为1中定义的模块 pass class InstanceTypes(BASE, NovaBase): __tablename__ = \"instance_types\" # 数据库中表的名称 id = Column(Integer, primary_key=True) #Column 用于定义数据表 \"instance_types”的字段， 其参数是该字段的具体的类型 name = Column(String(255)) memory_mb = Column(Integer) vcpus = Column(Integer) root_gb = Column(Integer) ephemeral_gb = Column(Integer) flavorid = Column(String(255)) swap = Column(Integer, nullable=False, default=0) rxtx_factor = Column(Float, nullable=False, default=1) vcpu_weight = Column(Integer, nullable=True) disabled = Column(Boolean, default=False) is_public = Column(Boolean, default=True)","link":"/2019/07/19/2014-05-16-using-sqlalchemy-crud-openstack-nova-flavors/"},{"title":"VM Failes to start with error: VDI not available","text":"触发条件: Ssh 至 VM内部，执行关机命令(shutdown -h now), 在NFS backend下的Vm通过Cloudstack无法启动 产生原因：Xenserver 与存储设备或者Lun失去连接 解决方法： Extract VDI UUID of Virtual Machine(VM) that is failing to start from /var/log/cloud/management/management-server.log file For example, VDI UUID will be 6f97582c-xxxx-xxxx-xxxx-9aa5686bcbd36. VM are failing to start with “errorInfo: [SR_BACKEND_FAILURE_46, The VDI is not available [opterr=VDI6f97582c-xxxx-xxxx-xxxx-9aa5686bcbd36 already attached RW]” error Connect to XenServer and make a note of the SR UUID and name-label of the VDI # xe vdi-list uuid= params=sr-uuid, name-label Run the following commands in XenServer # xe vdi-forget uuid= # xe sr-scan uuid= # xe vdi-param-set uuid=< volume extracted from step1 > name-label=< name label extracted from step2 > Restart Cloudstack Management Service","link":"/2019/07/19/2014-05-18-vm-failes-to-start-with-error-vdi-not-available/"},{"title":"Openstack Havana Neutron 虚拟网络设备分析","text":"Openstack网络设计中有：Tap设备、veth对，linux 桥接、OvS 桥接四中虚拟网络设备。对于一个流经vm中的eth0到物理host的eth1的以太网数据帧来说，要利用host上的9个设备完成：Tap设备vnet0(vm nic),linux 桥接qbrXXX, veth pair(qvbXXX,qvoXXX),Open vSwitch 桥接br-int, veth pair(intbr-eth1,phy-br-eth1),以及最后的物理主机的网卡eth1。 Tap设备:例如KVM、Xen虚拟一个网卡（通常称作VIF或者vNIC）vnet0,供vm使用。Guest OS因此接收到所有发送到Tap设备的以太网数据帧。 Veth pairs 是一对直接相连的虚拟网卡（virtual network interfaces），发送到veth对中的任意一方的以太网数据帧，另一方也会接收到。网络因此利用veth pairs作为VPC(virtual patch cables)来连接virtual bridges. Linux brige 象一个hub一样，可以将多个网络设备，包括物理或者虚拟机的，连接到一个Linux 桥接设备上。以太网数据帧会在hub上相连的的所有网络设备上进行传输 Open vSwitch 桥接设备的想一个虚拟的交换机，网卡连接到OVS 桥街上的端口，端口可以象物理交换机一样，对其进行配置VLAN等信息 由于openstack现在的防火墙的实现机制，使得不能够直接将Tap设备（vnet0、vnet1……）直接接入到桥接设备br-int(like a hub).防火墙实现机制是在tap设备上通过iptables实现防火墙，但是OVS又不支持直接连接到OVS port上的tap设备上的iptables 因此，网络设计上，增加了一个Linux 桥接设备以及一个veth pair来解决这个问题。将tap设备vnet0连接到linux bridge上（qbrXXX），而不是直接到连到ovs的桥街上，这个ovs桥接设备通过（qvbXXX,qvoXXX）veth pair连接到br-int(linke a hub)上 [root@devstack:keystone_admin ~]# brctl show bridge name bridge id STP enabled interfaces qbr69e73747-c0 8000.52a89a03f5a9 no qvb69e73747-c0 qbrff6ee26c-fc 8000.febb4e384e96 no qvbff6ee26c-fc","link":"/2019/07/19/2014-05-19-openstack-havana-virtual-networking-devices/"},{"title":"Libvirt Virsh Commands","text":"##Libvirt Virsh 命令 ###磁盘文件 查看domain的挂载的磁盘信息 virsh domblklist instance-0000002d vda /opt/stack/data/nova/instances/f8780dbc-e2fd-46e9-ae0c-9a654d4eb95a/disk vdb /opt/stack/data/nova/instances/f8780dbc-e2fd-46e9-ae0c-9a654d4eb95a/disk.local vdc /opt/stack/data/nova/instances/f8780dbc-e2fd-46e9-ae0c-9a654d4eb95a/disk.swap vdd /dev/disk/by-path/ip-192.168.0.28:3260-iscsi-iqn.2010-10.org.openstack:volume-7c9646ef-e1f1-4da4-b230-c4ec7679bb6a-lun-1 查看磁盘文件状态 virsh domblkstat instance-0000002d vda vda rd_req 7970 vda rd_bytes 214534656 vda wr_req 1503 vda wr_bytes 247596032 vda flush_operations 182 vda rd_total_times 32382476906 vda wr_total_times 646733610926 vda flush_total_times 214371604","link":"/2019/07/19/2014-05-24-libvirt-virsh-commands/"},{"title":"Git Commands Related","text":"撤销某次提交，恢复删除的文件 通过git log 命令查找到想要恢复的commit id号 commit cf9cb9fea61d5adeaf8967f2d51b04b3fd995a0e Author: Yitao Jiang Date: Thu Apr 17 00:03:21 2014 +0800 Delete tags. git revert cf9cb9fea61d5adeaf8967f2d51b04b3fd995a0e [root@dvlp jiangyt.github.io]# git revert cf9cb9fea61d5adeaf8967f2d51b04b3fd995a0e Finished one revert. Revert tags.html and Upload new posts This reverts commit cf9cb9fea61d5adeaf8967f2d51b04b3fd995a0e. # Please enter the commit message for your changes. Lines starting # with '#' will be ignored, and an empty message aborts the commit. # On branch master$ # Changes to be committed:$ # (use \"git reset HEAD ...\" to unstage) # # new file: tags.html 保存，退出后:wq 文件已恢复 查看当前提交记录 git log commit bba1aaa176b12a5abd47f852cbb28f187d1d5e5d Author: Yitao Jiang Date: Sun May 25 22:12:12 2014 +0800 Revert tags.html and Upload new posts This reverts commit cf9cb9fea61d5adeaf8967f2d51b04b3fd995a0e. 可以看到在revert后，产生的commit记录中包含revert的commit id号","link":"/2019/07/19/2014-05-25-git-commands-related/"},{"title":"Linux Iscsi Server Client Settings","text":"#服务器端 ###创建ISCSI设备 tgtadm –lld iscsi –op new –mode target –tid 2 -T iqn.cloud.test:storage.disk2 tgtadm –lld iscsi –op new –mode logicalunit –tid 2 –lun 2 -b /dev/sdg #添加设备 tgtadm –lld iscsi –op bind –mode target –tid 2 -I ALL # 赋权 #客户端 iscsiadm -m discoverydb [ -hV ] [ -d debug_level ] [-P printlevel] [ -t type -p ip:port -I ifaceN … [ -Dl ] ] | [ [ -p ip:port -t type] [ -o operation ] [ -n name ] [ -v value ] [ -lD ] ] 客户端查看Iscsi设备 iscsiadm -m discovery [ -hV ] [ -d debug_level ] [-P printlevel] [ -t type -p ip:port -I ifaceN … [ -l ] ] | [ [ -p ip:port ] [ -l | -D ] ] [root@devstack:keystone_admin images]# iscsiadm -m discovery -t sendtargets -p 127.0.0.1 127.0.0.1:3260,1 iqn.2010-10.org.openstack:volume-7c9646ef-e1f1-4da4-b230-c4ec7679bb6a 执行命令 iscsiadm -m node [ -hV ] [ -d debug_level ] [ -P printlevel ] [ -L all,manual,automatic ] [ -U all,manual,automatic ] [ -S ] [ [ -T targetname -p ip:port -I ifaceN ] [ -l | -u | -R | -s] ] [ [ -o operation ] [ -n name ] [ -v value ] ] ####查看设备 [root@devstack nova]# iscsiadm -m node -T iqn.2010-10.org.openstack:volume-7c9646ef-e1f1-4da4-b230-c4ec7679bb6a --login Logging in to [iface: default, target: iqn.2010-10.org.openstack:volume-7c9646ef-e1f1-4da4-b230-c4ec7679bb6a, portal: 192.168.0.28,3260] (multiple)Logging in to [iface: default, target: iqn.2010-10.org.openstack:volume-7c9646ef-e1f1-4da4-b230-c4ec7679bb6a, portal: 127.0.0.1,3260] (multiple)Login to [iface: default, target: iqn.2010-10.org.openstack:volume-7c9646ef-e1f1-4da4-b230-c4ec7679bb6a, portal: 192.168.0.28,3260] successful.Login to [iface: default, target: iqn.2010-10.org.openstack:volume-7c9646ef-e1f1-4da4-b230-c4ec7679bb6a, portal: 127.0.0.1,3260] successful. fdisk -l iscsiadm -m session [ -hV ] [ -d debug_level ] [ -P printlevel] [ -r sessionid | sysfsdir [ -R | -u | -s ] [ -o operation ] [ -n name ] [ -v value ] ] iscsiadm -m iface [ -hV ] [ -d debug_level ] [ -P printlevel ] [ -I ifacename | -H hostno|MAC ] [ [ -o operation ] [ -n name ] [ -v value ] ] [ -C ping [ -a ip ] [ -b packetsize ] [ -c count ] [ -i interval ] ] iscsiadm -m fw [ -l ] iscsiadm -m host [ -P printlevel ] [ -H hostno|MAC ] [ [ -C chap [ -o operation ] [ -v chap_tbl_idx ] ] | [ -C flashnode [ -o operation ] [ -A portal_type ] [ -x flashnode_idx ] [ -n name ] [ -v value ] ] ]iscsiadm -k priority #使用中遇到的问题 ###iscsiadm: Could not perform SendTargets discovery iscsiadm -m discovery -t sendtargets -p 192.168.127.2 iscsiadm: Could not scan /sys/class/iscsi_transport. iscsiadm: Could not scan /sys/class/iscsi_transport. iscsiadm: can not connect to iSCSI daemon (111)! iscsiadm: Cannot perform discovery. Initiatorname required. iscsiadm: Discovery process to 192.168.127.2:3260 failed to create a discovery session. iscsiadm: Could not perform SendTargets discovery. 是因为没有安装iCSCI daemon ubuntu下安装 open-iscsi（apt-get install open-iscsi） Linux（Centos 6.4）下安装iscsi-initiator-utils-6.2.0.873-10.el6.x86_64","link":"/2019/07/19/2014-05-25-linux-iscsi-server-client-settings/"},{"title":"OpenVAS Related","text":"##网络安全相关词语 NVP Network Vulnerability Test CVE Common Vulnerabilities and Exposure","link":"/2019/07/19/2014-05-25-openvas-related/"},{"title":"MySQL Lost Connection","text":"##Navicat连接mysql数据库连接错误Code 2013 Lost connection ###现象 2013 - Lost connection to Mysql Server at ‘waiting for initial communication packet’, system error:0 ###解决方法在mysql的配置文件my.cnf 或my.ini 下添加 skip_name_resolve 使其在与mysql服务器建立连接时，跳过主机名的解析","link":"/2019/07/19/2014-05-29-mysql-lost-connection/"},{"title":"Git Revert Merge","text":"##Git Merge命令的使用及撤销 Git 的 revert 命令可以用来撤销提交（commit），对于常规的提交来说，revert 命令十分直观易用，相当于做一次被 revert 的提交的「反操作」并形成一个新的 commit，但是当你需要撤销一个合并（merge）的时候，事情就变得稍微复杂了一些。 ###Merge Commit在描述 merge commit 之前，先来简短地描述一下常规的 commit。每当你做了一批操作（增加、修改、或删除）之后，你执行 git commit 便会得到一个常规的 Commit。执行 git show &lt;commit&gt;将会输出详细的增删情况。 但是Merge commit 不是这样。每当你使用 git merge 合并两个分支，你将会得到一个新的 merge commit。执行 git show 之后，会有类似的输出： 1 commit 19b7d40d2ebefb4236a8ab630f89e4afca6e9dbe 2 Merge: b0ef24a cca45f9 3 ...... 其中，Merge 这一行代表的是这个合并 parents，它可以用来表明 merge 操作的线索。 举个例子，通常，我们的稳定代码都在 master 分支，而开发过程使用 dev 分支，当开发完成后，再把 dev 分支 merge 进 master 分支： a -> b -> c -> f -- g -> h (master) \\ / d -> e (dev) 上图中，g 是 merge commit，其他的都是常规 commit。g 的两个 parent 分别是 f 和 e。 ###Revert a Merge Commit(撤销merge操作)当你使用 git revert 撤销一个 merge commit 时，如果除了 commit 号而不加任何其他参数，git 将会提示错误： 1 $ git revert g 2 error: Commit g is a merge but no -m option was given. 3 fatal: revert failed 这是由于，在你合并两个分支并试图撤销时，Git 并不知道你到底需要保留哪一个分支上所做的修改。从 Git 的角度来看，master 分支和 dev 在地位上是完全平等的，只是在 workflow 中，master 被人为约定成了「主分支」。 于是是 Git 需要你通过 m 或 mainline 参数来指定「主线」。merge commit 的 parents 一定是在两个不同的线索上，因此可以通过 parent 来表示「主线」。m 参数的值可以是 1 或者 2，对应着 parent 在 merge commit 信息中的顺序。 以上面那张图为例，我们查看 commit g 的内容： $ git show g commit g Merge: f e 那么$ git revert -m 1 g 将会保留 master 分支上的修改，撤销 dev 分支上的修改。 撤销成功之后，Git 将会生成一个新的 Commit，提交历史就成了这样： a -> b -> c -> f -- g -> h -> G (master) \\ / d -> e (dev) 其中 G 是撤销 g 生成的 commit。通过 $ git show G 之后，我们会发现 G 是一个常规提交，内容就是撤销 merge 时被丢弃的那条线索的所有 commit 的「反操作」的合集。 上面的提交历史在实践中通常对应着这样的情况： 工程师在 master 分支切出了 dev 分支编写新功能，开发完成后合并 dev 分支到 master 分支并上线。上线之后，发现了 dev 分支引入了严重的 bug，而其他人已经在最新的 master 上切出了新的分支并进行开发，所以不能简单地在 master 分支上通过重置（git reset ）来回滚代码，只能选择 revert 那个 merge commit。 但是事情还没有结束。工程师必须切回 dev 分支修复那些 bug，于是提交记录变成了这个样子： a -> b -> c -> f -- g -> h -> G -> i (master) \\ / d -> e -> j -> k (dev) 工程师返回 dev 分支通过 j，k 两个 commit 修复了 bug，其他工程师在 master 上有了新的提交 i。现在到了 dev 分支的内容重新上线的时候了。 直觉上来说，还是和之前一样，把 dev 分支合并到 master 分支就好了。于是： $ git checkout master $ git merge dev 得到的提交记录变成了这样： a -> b -> c -> f -- g -> h -> G -> i -- m (master) \\ / / d -> e -> j -> k --------- (dev) m是新的 merge commit。需要注意的是，这不能得到我们期望的结果。因为 d 和 e 两个提交曾经被丢弃过，如此合并到 master 的代码，并不会重新包含 d 和e 两个提交的内容，相当于只有 dev 上的新 commit 被合并了进来，而 dev 分支之前的内容，依然是被 revert 掉了。 所以，如果想恢复整个 dev 所做的修改，应该： $ git checkout master $ git revert G $ git merge dev 于是，提交历史变成了这样： a -> b -> c -> f -- g -> h -> G -> i -> G' -- m (master) \\ / / d -> e -> j -> k --------------- (dev) 其中 G&#39; 是这次 revert 操作生成的 commit，把之前撤销合并时丢弃的代码恢复了回来，然后再 merge dev 分支，把解 bug 写的新代码合并到 master 分支。 现在，工程师可以放心地上线没有 bug 的新功能了。","link":"/2019/07/19/2014-05-30-git-revert-merge/"},{"title":"Cloudstack Cli Cloudmonkey Installation","text":"##Cli安装使用分为四部分 安装virtualenv 安装cloudmonkey 配置cloudmonkey 命令使用 安装virtualenv1. virtualenv提供了一个安装软件时的测试环境，所安装的软件不会安装在系统目录下 2. 安装python2.7.4 时的依赖软件， 此步骤可选， cloudmonkey 要求python版本在2.5以上即可 3. yum -y groupinstall &quot;Development tools&quot; zlib-devel bzip2-devel openssl-devel ncurses-devel mysql-devel ibxml2-devel libxslt-devel unixODBC-devel sqlite sqlite-devel源码安装python2.7.4wget http://www.python.org/ftp/python/2.7.4/Python-2.7.4.tar.bz2 tar xf Python-2.7.4.tar.bz2 cd Python-2.7.4 /configure --prefix=/opt/python2.7 make && make altinstall` ##源码安装virtualenv wget https://pypi.python.org/packages/source/v/virtualenv/virtualenv-1.9.1.tar.gz#md5=07e09df0adfca0b2d487e39a4bf2270a tar -xvzf virtualenv-1.9.1.tar.gz python virtualenv -1.9.1/setup.py install ###安装cloudmonkey 建立virtualenv环境 #mkidr workenv #virtualenv worksenv #source worksenv/bin/activate 安装cloudmonkey两种方式任选其一 2.1. 通过python库安装 在系统安装了pip后或者env生效后执行下面命令 #$ pip install cloudmonkey 2.2. 通过源码安装将打包后的源码上传至服务器中解压缩打包后的文件安装 # python setup.py build # # python setup.py install 配置cloudmonkey #cloudmonkey > set history_file /usr/share/cloudmonkey_history > set log_file /var/log/cloudmonkey 设置管理服务器 > set host 192.168.56.1 设置端口 > set port 8080 设置使用的apikey > set apikey {put-your-api-key-for-your-user} 设置使用的secretkey > set secretkey {put-your-secret-key-for-your-user} 修改cloudmonkey终端提示符 > set prompt smcloudcli> 同步配置 > sync 324 APIs discovered and cached 配置结束。通常情况下，所有配置项在 ~/.cloudmonkey/config: 均可见 命令使用tab健可以命令补全 #cloudmonkey 加载用户的key smcloudcli>sync smcloudcli>list 设置数据显示方式为table smcloudcli>set display table 设置数据显示方式为json smcloudcli>set display json smcloudcli>list users","link":"/2019/07/19/2014-06-01-cloudstack-cli-cloudmonkey-installation/"},{"title":"Instance start failed because mismatch in VR ssh key Pair","text":"ExceptionFailed to authentication SSH user root on host 10.147.40.1642013-06-15 01:36:13,977 ERROR [vmware.resource.VmwareResource] (DirectAgent-18:10.147.40.30) Unable to execute NetworkUsage command on DomR (10.147.40.164), domR may not be ready yet. failure due to Exception: java.lang.ExceptionMessage: Failed to authentication SSH user root on host 10.147.40.164java.lang.Exception: Failed to authentication SSH user root on host 10.147.40.164at com.cloud.utils.ssh.SshHelper.sshExecute(SshHelper.java:144)at com.cloud.utils.ssh.SshHelper.sshExecute(SshHelper.java:37)at com.cloud.hypervisor.vmware.resource.VmwareResource.networkUsage(VmwareResource.java:5451)at com.cloud.hypervisor.vmware.resource.VmwareResource.execute(VmwareResource.java:2301)at com.cloud.hypervisor.vmware.resource.VmwareResource.executeRequest(VmwareResource.java:480)at com.cloud.agent.manager.DirectAgentAttache$Task.run(DirectAgentAttache.java:186)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)at java.util.concurrent.FutureTask.run(FutureTask.java:166)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)at java.lang.Thread.run(Thread.java:679)2013-06-15 01:36:13,980 DEBUG [vmware.resource.VmwareResource] (DirectAgent-18:10.147.40.30) Executing resource GetDomRVersionCmd: {“accessDetails”:{“router.ip”:”10.147.40.164”,”router.name”:”r-8-VM”},”wait”:0}2013-06-15 01:36:13,980 DEBUG [vmware.resource.VmwareResource] (DirectAgent-18:10.147.40.30) Run command on domR 10.147.40.164, /opt/cloud/bin/get_template_version.sh2013-06-15 01:36:13,981 DEBUG [vmware.resource.VmwareResource] (DirectAgent-18:10.147.40.30) Use router’s private IP for SSH control. IP : 10.147.40.1642013-06-15 01:36:14,081 DEBUG [cloud.api.ApiServlet] (catalina-exec-12:null) ===START=== 10.101.255.119 – GET command=queryAsyncJobResult&amp;jobId=43dde7f6-fb5d-4ead-8691-5071feb44dfd&amp;response=json&amp;sessionkey=tN07%2BJ4GVSCHGNV%2FPjdO3V%2Bs3Tg%3D&amp;=13712208480202013-06-15 01:36:14,163 DEBUG [cloud.api.ApiServlet] (catalina-exec-12:null) ===END=== 10.101.255.119 – GET command=queryAsyncJobResult&amp;jobId=43dde7f6-fb5d-4ead-8691-5071feb44dfd&amp;response=json&amp;sessionkey=tN07%2BJ4GVSCHGNV%2FPjdO3V%2Bs3Tg%3D&amp;=13712208480202013-06-15 01:36:14,231 ERROR [utils.ssh.SshHelper] (DirectAgent-18:10.147.40.30) Failed to authentication SSH user root on host 10.147.40.1642013-06-15 01:36:14,235 ERROR [vmware.resource.VmwareResource] (DirectAgent-18:10.147.40.30) GetDomRVersionCmd failed due to Exception: java.lang.ExceptionMessage: Failed to authentication SSH user root on host 10.147.40.164java.lang.Exception: Failed to authentication SSH user root on host 10.147.40.164at com.cloud.utils.ssh.SshHelper.sshExecute(SshHelper.java:144)at com.cloud.utils.ssh.SshHelper.sshExecute(SshHelper.java:37)at com.cloud.hypervisor.vmware.resource.VmwareResource.execute(VmwareResource.java:2143)at com.cloud.hypervisor.vmware.resource.VmwareResource.executeRequest(VmwareResource.java:488)at com.cloud.agent.manager.DirectAgentAttache$Task.run(DirectAgentAttache.java:186)at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:471)at java.util.concurrent.FutureTask$Sync.innerRun(FutureTask.java:334)at java.util.concurrent.FutureTask.run(FutureTask.java:166)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.access$101(ScheduledThreadPoolExecutor.java:165)at java.util.concurrent.ScheduledThreadPoolExecutor$ScheduledFutureTask.run(ScheduledThreadPoolExecutor.java:266)at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1110)at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:603)at java.lang.Thread.run(Thread.java:679)2013-06-15 01:36:14,237 DEBUG [agent.manager.DirectAgentAttache] (DirectAgent-18:null) Seq 1-965476380: Cancelling because one of the answers is false and it is stop on error.2013-06-15 01:36:14,238 DEBUG [agent.manager.DirectAgentAttache] (DirectAgent-18:null) Seq 1-965476380: Response Received ##Solutions [root@ms2 ~]# cat /var/cloudstack/management/.ssh/id_rsa.pubssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAuqhNj72tdEVhc/Cbph6EyPLcPm6KKrgVMdFKXRn7uW5S6UT+QqtM4ec7S0lA0roVsbnst2/DdLQZhCcBDMggRRP7BJSM1O5cXcFQib+gwAaneaUwomVMPiA/uAdCJBxgId5qTZw4cyWnemLkkZTcta96aIIhT0/ycal4PMPbXRE9u78RRVeoo19BnjAYd6o7zo+O8fNaRLdQRTcpGCm5KTQRhKREOA/OREHvX0mBuuEAie74e3QVd+ZA/6kQ7uspKsFnQTWEM0I8YR2UPj9JL1pyPAawV3QiycEOaChYhUZ6DcuebEJEbzahiRbtBnDkRz+gQ/TpHx96pmAzzDaQyQ==cloud@ms2[root@ms2 ~]# ###Mount System ISO[root@ms2 ~]# mkdir /tmp/is[root@ms2 ~]# mount -o loop /var/cloudstack/mnt/VM/7566222426160.3051fff0/systemvm/systemvm-4.2.0-SNAPSHOT.iso root@ms2 ~]# cd /tmp/is/ [root@ms2 is]# lsauthorized_keys cloud-scripts.tgz systemvm.zip [root@ms2 is]# cat authorized_keysssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAv2Ym6oJKNnSiMPg0F/RxNhCNvmiB0HJwWLbWC0GQLkB6/Q7F93X8jConFbjehQqBPXePZhEV8veGyH8AmjRDlnP42qpxvCsOnD7BGrXm+Uv+/VovzZ719wcMny0GO2spJgpJcut0YrJqr9OXRlrgbis9dweeB0SyZDKT2ja4c6V2E2Fo9D7BdqWg2S2ptKW7oNkL6846Rfa9/WHh0PO7DmJ5mIuJbazNfBOM0SH6M2FOORgBFytC2XEf0o2aYHGDKOyuwDb2YOuThfDNP3r29qhRUHdZY8Ozs9S0iF+m/L3vBvuOCk0eJMjuYJnsuMTH7KScP5GILurlBCaU9vXmvw== cloud@ms2 We can see that the private keys are not equal, so we update the system.iso with correct authorized_keys, and then replace system.iso, destroy ssvm ,cpvm along with it’s base template image within hypervisor, then the new system vms will be bring up. Now you can deploy you virtual machines","link":"/2019/07/19/2014-09-03-instance-start-failed-because-mis-match-in-vr-ssh-key-pair/"},{"title":"How To Change Xenserver Default Installtion Partitions","text":"修改root磁盘大小开机选择F2高级模式，输入shell， vi /opt/xensource/installer/constants.py DOM0_MEM=752为DOM0_MEM=2940, 修改root_size=4096为 root_size=10240 输入EXIT修改内存XenServerDomain0默认使用752MB内存，由于每启动一台虚拟机，Domain0中就会启动一个Qemu-DM的进程，占用大约6M的内存空间， 因此在虚拟机数量较多的情况下，我们需要增大Domain0内存以便支持更多的虚拟机运行。 由于Domain0是32位操作系统，故支持的最大内存量为4GB。 更改Domain0内存的方法参考CTX124806-XenServerSingleServerScalabilitywithXenDesktop提到的例子， 更改/boot/exlinux.conf下包含dom0_mem=2940M的Xen命令行。为了修改先前的设置，完成下面的步骤： 通过XenCenter的控制口或者SSH方式以root身份登录到Domain0。 确保备份一份原始的/boot/extlinux.conf文件。以免未来的修改导致XenServer不能启动。 用vi打开/boot/extlinux.conf。 下面的改动仅添加到labelxe和labelxe-serial部分。 ###进行下面的改动：labelxe#XenServerkernelmboot.c32append/boot/xen.gzdom0_mem=752Mlowmem_emergency_pool=1Mcrashkernel=64M@32Mconsole=com1vga=mode-0x0311—/boot/vmlinuz-2.6-xenroot=LABEL=root-ecpmuteuroxencons=hvcconsole=hvc0console=tty0quietvga=785splash—/boot/initrd-2.6-xen.img ###改变为:labelxe#XenServerkernelmboot.c32append/boot/xen.gzdom0_mem=2940Mlowmem_emergency_pool=1Mcrashkernel=64M@32Mconsole=com1vga=mode-0x0311—/boot/vmlinuz-2.6-xenroot=LABEL=root-ecpmuteuroxencons=hvcconsole=hvc0console=tty0quietvga=785splash—/boot/initrd-2.6-xen.img 调整Dom0内存设置dom0_mem=2940M是为了分配给dom0更多的内存，这意味着它可以更好地处理更多数量的虚拟机。在改变了这个设置并重启以确保新配置的dom0内存大小生效","link":"/2019/07/19/2014-12-01-how-to-change-xenserver-default-installtion-partitions/"},{"title":"How To Publish Events Into AMPQ/Rabbitmq Within Cloudstack 4.4.1","text":"#####Currently within cloudstack all events are stored in DB and the only to retrive events is using APIS which is not so convient.Since 4.1.0, Apache CloudStack began to support publishing interesting events from the management servers onto a message queue. The current implementation of that feature uses RabbitMQ as the message broker.Fowllowings are the steps to enable such feature.###Install Rabbitmq-server Following the instructions from here:http://www.rabbitmq.com/download.html to setup rabbitmq-server Make sure that rabbitmq-server running, and (/or) enable rabbitmq-management webui plugin ###Configure CloudstackAssuming you have setup cloudstack management server and have mq server running with correct user credential(Default user is guest/guest) In cloudstack management server Create spring event bus related configuration file mdir -p /usr/share/cloudstack-management/webapps/client/WEB-INF/classes/META-INF/cloudstack/core [root@cs-mgmt core]# cat spring-event-bus-context.xml < beans xmlns=\"http://www.springframework.org/schema/beans\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:context=\"http://www.springframework.org/schema/context\" xmlns:aop=\"http://www.springframework.org/schema/aop\" xmlns:util=\"http://www.springframework.org/schema/util\" xsi:schemaLocation=\"http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans-3.0.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop-3.0.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context-3.0.xsd http://www.springframework.org/schema/util http://www.springframework.org/schema/util/spring-util-3.0.xsd\" > < bean id=\"eventNotificationBus\" class=\"org.apache.cloudstack.mom.rabbitmq.RabbitMQEventBus\"> < property name=\"name\" value=\"eventNotificationBus\" /> < property name=\"server\" value=\"localhost\" /> < property name=\"port\" value=\"5672\" /> < property name=\"username\" value=\"guest\" /> < property name=\"password\" value=\"guest\" /> < property name=\"exchange\" value=\"cloudstack-events\" /> < /bean> < /beans> restart cloudstack management service /etc/init.d/cloudstack-management restart ###Check Exchange status Using rabbitmqctl to check the status exchanges of current node. [root@cs-mgmt core]# rabbitmqctl list_exchanges Listing exchanges ... direct amq.direct direct amq.fanout fanout amq.headers headers amq.match headers amq.rabbitmq.log topic amq.rabbitmq.trace topic amq.topic topic cloudstack-events topic ...done. [root@cs-mgmt core]# We can see that cloudstack has connected to rabbitmq server.","link":"/2019/07/19/2014-12-17-how-to-publish-events-into-ampqrabbitmq-within-cloudstack-441/"},{"title":"PowerDNS Configuration For Single Node","text":"Configuration For Single Host#####The guide is used for setup a single node powerdns with mysql backend under openstack Installation Launch a powerdns instance using image ubuntu 14.04, associate floatingip ssh into instance then run following commands sudo apt-get update sudo apt-get install mysql-server mysql-common pdns-server pdns-backend-mysql WHEN INSTALLING MYSQL-SERVER, REMEMBER THE ROOT PASSWORD OF DATABASE FOR LATER USE Configuration configure mysql-server edit /etc/mysql/my.cnf bind-address = 127.0.0.1 restart mysql-server Create powerdns database Now that you have created a database, you need to add a user that will have access to that database. For simplify we are using root user, otherwise create use and grant access to database. Next, you create the database required for your install of PowerDNS: create database pdns; use pdns; create table domains ( id INT auto_increment, name VARCHAR(255) NOT NULL, master VARCHAR(128) DEFAULT NULL, last_check INT DEFAULT NULL, type VARCHAR(6) NOT NULL, notified_serial INT DEFAULT NULL, account VARCHAR(40) DEFAULT NULL, primary key (id) ) Engine=InnoDB; CREATE UNIQUE INDEX name_index ON domains(name); CREATE TABLE records ( id INT auto_increment, domain_id INT DEFAULT NULL, name VARCHAR(255) DEFAULT NULL, type VARCHAR(10) DEFAULT NULL, content VARCHAR(64000) DEFAULT NULL, ttl INT DEFAULT NULL, prio INT DEFAULT NULL, change_date INT DEFAULT NULL, primary key(id) ) Engine=InnoDB; CREATE INDEX nametype_index ON records(name,type); CREATE INDEX domain_id ON records(domain_id); create table supermasters ( ip VARCHAR(64) NOT NULL, nameserver VARCHAR(255) NOT NULL, account VARCHAR(40) DEFAULT NULL ) Engine=InnoDB; Now, leave the MySQL shell with: quit; modify powerdns server cd /etc/powerdns mv pdns.conf pdns.conf.bak cp pdns.d/pdns.local.gmysql.conf pdns.conf then modify pdns.conf change to the db credentials created above. Finally, restart your PowerDNS service with the following: sudo service pdns restart Admin Web UI Poweradmin writen in php give you a web dashboard for operating dns record, much more convinent. Install the prerequisites $ sudo apt-get install apache2 libapache2-mod-php5 php5 php5-common php5-curl php5-dev php5-gd php-pear php5-imap php5-mcrypt php5-common php5-ming php5-mysql php5-xmlrpc gettext $sudo pear install MDB2 $sudo pear install MDB2_Driver_mysql Download poweradmin release $cd /tmp wget https://github.com/downloads/Poweradmin/Poweradmin/Poweradmin-2.1.6.tgz tar xvfz Poweradmin-2.1.6.tgz mv Poweradmin-2.1.6 /var/www/html/Poweradmin touch /var/www/html/Poweradmin/inc/config.inc.php chown -R www-data:www-data /var/www/html/Poweradmin/` Now open a browser and launch the web-based Poweradmin installer (http:///poweradmin/install). Following the guide to setup admin ui. After installation, install subfolder under /var/www/html/Poweradmin need to be removed or migrated, then go to http:///Poweradmin//index.php to setup dns records FAQ Can not launch powerdns admin installer Login to the powerdns machine, disable firewall of add the tcp:80 port to the INPUT chain, restart apache2 service Mysql crypto releate issue Make sure php5-mcrypt installed(yum install php5-mcrypt) modify configuration for php root@powerdns-cli-01:/etc/php5# find / -name mcrypt.so /usr/lib/php5/20121212/mcrypt.so root@powerdns-cli-01:/etc/php5# cat cli/conf.d/20-mcrypt.ini ; configuration for php MCrypt module extension=/usr/lib/php5/20121212/mcrypt.so` References https://doc.powerdns.com/md/authoritative/installation/ Google","link":"/2019/07/19/2015-05-06-powerdns-configuration-for-single-node/"},{"title":"Docker   Enter a Running Container With New TTY","text":"Generic Method - Docker EnterSince docker 1.3, you can use docker exec -it [container-id] bash. To make this easier, I create a file at/usr/bin/docker-enter with the following contents. #!/bin/bash EXPECTED_NUM_ARGS=1; if [ \"$#\" -ne $EXPECTED_NUM_ARGS ]; then CONTAINER_ID=`/usr/bin/docker ps -q --no-trunc | /bin/sed -n 1p` /usr/bin/docker exec -it $CONTAINER_ID bash else /usr/bin/docker exec -it $1 bash fi Now you can just run docker-enter $container-id or if you just want to enter the last container you spawned, just run the command docker-enter","link":"/2019/07/19/2015-06-10-docker---enter-a-running-container-with-new-tty/"},{"title":"","text":"This introduction will outline specifically how to run sudo without password under redhat OS. First you need to check what privileges you have now, run command as belows [yitao@yitao-dev bumblebee]$ sudo -l Matching Defaults entries for yitao on this host: requiretty, !visiblepw, always_set_home, env_reset, env_keep=”COLORS DISPLAY HOSTNAME HISTSIZE INPUTRC KDEDIR LS_COLORS”, env_keep+=”MAIL PS1 PS2 QTDIR USERNAME LANG LC_ADDRESS LC_CTYPE”, env_keep+=”LC_COLLATE LC_IDENTIFICATION LC_MEASUREMENT LC_MESSAGES”, env_keep+=”LC_MONETARY LC_NAME LC_NUMERIC LC_PAPER LC_TELEPHONE”, env_keep+=”LC_TIME LC_ALL LANGUAGE LINGUAS _XKB_CHARSET XAUTHORITY”, secure_path=/sbin:/bin:/usr/sbin:/usr/bin Runas and Command-specific defaults for yitao: Defaults&gt;root !requiretty User yitao may run the following commands on this host: (ALL) ALL (root) NOPASSWD: /usr/bin/usb-luks-encrypt (root) NOPASSWD: /usr/bin/imagewriter 2.Add the privilege, run the command as follows [yitao@yitao-dev bumblebee]$ sudo visudo INPUT YOUR ROOT PASSWORD TO ACCESS THE VISUDO FILE Then add a record to the last line, to be specific, after the last line which says #includedir /etc/sudoers.d ... Defaults&gt;root !requiretty # Line required by usb usb-luks-encrypt ALL ALL=(root) NOPASSWD: /usr/bin/usb-luks-encrypt ALL ALL=(root) NOPASSWD: /usr/bin/imagewriter ***YOUR_NAME_HERE*** ALL=(ALL) NOPASSWD: ALLexit. Now you can sudo command without password. Written with StackEdit.","link":"/2019/07/19/2015-07-10-sudo-witout-password-redhat/"},{"title":"","text":"This introduction will outline specifically on how to show tab name on an active screen Linux screen is a very powerful tool for sysadmin when you need to run a long running process without kept your computer connecting to the remote server here is the deatils introductions about Screen There is two ways to display tab name Configure .screenrc Add this to your .screenrc file: `caption always &quot;%{= kw}%-w%{= BW}%n %t%{-}%+w %-= @%H - %LD %d %LM - %c&quot;` After you restart your screen, there&apos;s a status bar below showing the current tab name, and as a bonus your current host name and time -- modify them away at will if you so wish. To rename a tab, press ctrl+a A and give it a new name. Operate at existing screen Sometimes you create a screen but havn’t enable captions, it’s not convient to switch among tabs, you can run following commands to enable screen tabs First you need to detach current screen ctrl + a +d screen -S &lt;YOUR SCREEN NAME HERE&gt; -X caption always &quot;%{= kw}%-w%{= BW}%n %t%{-}%+w %-= @%H - %LD %d %LM - %c&quot; Attach to your screen screen -r &lt;YOUR SCREEN NAME HERE&gt; Now your screen will be looks like this","link":"/2019/07/19/2015-07-21-howto-enable-linux-screen-tabs-name/"},{"title":"","text":"This introduction will outline specifically how to setup a private docker registry and how building a debian based docker image for later use. OverviewThe following commands run on redhat 6.5 Set up docker Registry RequirementsThe Registry is compatible with Docker engine version 1.6.0 or higher. TL;DR# Start your registry docker run -d -p 5000:5000 registry:2 after the command over, you can see a running container It works. Build Debian Base Image(Jessie) ####First install debootstrap sudo yum install debootstrap ####Then prepare the root directory mkdir -p /vdisks/chroot/jessie ####Finally build a Jessie system sudo debootstrap jessie /vdisks/chroot/jessie http://ftp.us.debian.org/debian ####Waiting for the result ####… ####At this point you have a small environment which you can chroot into and modify it the way you like Import Image[yitao@yitao-dev ~]$ cd /vdisks/chroot/ [yitao@yitao-dev chroot]$ sudo tar -C jessie/ -c . | sudo docker import - debian-jessie 79911aebfadd3f5d4fb7a3b539ee658361909bea1e64d25385b5bbb97e4a1d0c Local images [yitao@yitao-dev ~]$ sudo docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE debian-jessie latest 79911aebfadd About a minute ago 274.8 MB registry 2 b4ad0b763f11 2 weeks ago 548.6 MBUpload Customize Image to Private Registry # Tag the image so that it points to your registry sudo docker tag debian-jessie localhost:5000/debian:jessie # Push it [yitao@yitao-dev chroot]$ sudo docker push localhost:5000/debian:jessie The push refers to a repository [localhost:5000/debian] (len: 1) 79911aebfadd: Image already exists Digest: sha256:a7769244195e4230119e8753acd015f3e2804321eb21fcadb200910cb9d93394 [yitao@yitao-dev chroot]$ # Pull it back [yitao@yitao-dev ~]$ sudo docker pull localhost:5000/debian:jessie jessie: Pulling from localhost:5000/debian 79911aebfadd: Already exists Digest: sha256:a7769244195e4230119e8753acd015f3e2804321eb21fcadb200910cb9d93394 Status: Image is up to date for localhost:5000/debian:jessie #start a new image [yitao@yitao-dev ~]$ sudo docker run --rm --name=jessie localhost:5000/debian:jessie cat /etc/issue.net Debian GNU/Linux 8Thank you.","link":"/2019/07/19/2015-08-03-How-To-Setup-private-docker-registry-and-build-a-debian-based-docker-image/"},{"title":"","text":"This introduction will outline specifically how to disable and enable IPV6 in RHEL 6.X OverviewThe following commands run on redhat 6.5 Problem:Need to disable the IPV6 in RedHat Enterprise Linux Solution: Disable IPV6 in RHEL: 1) Add the below line in the modprobe.conf file # vi /etc/modprobe.conf alias net-pf-10 off alias ipv6 off # Add this for RHEL before 5.4 options ipv6 disable=1 # Add this for 5.4 and laterNote : If any entry available like “alias net-pf-10 ipv6”, delete that entry. 2) Also add the below entry in the network file to prevent error # vi /etc/sysconfig/network NETWORKING_IPV6=no3) Reboot the server to disable the IPV6 # shutdown -r nowEnable IPV6 in RHEL: 4) Add the below entry in the modprobe.conf file # vi /etc/modprobe.conf alias net-pf-10 ipv6Note : Remove if any entry like “alias net-pf-10 off or alias ipv6 off or options ipv6 disable=1” in the modprobe.conf file. 5) Change the “ NETWORKING_IPV6” parameter value to yes in the netwok file. # vi /etc/sysconfig/network NETWORKING_IPV6=yes6) Restart the server to enable the IPV6 support # shutdown -r nowThank you.","link":"/2019/07/19/2015-10-01-How-To-enable-or-disable-ipv6-on-rhel/"},{"title":"","text":"This introduction will outline specifically how to install dependencies behind proxy under different code environment OverviewThe following commands run on redhat 6.5 1) python pip # pip install --proxy PROXY_INFOR XXX 2) Maven # vi $M2_HOME/conf/settings.xml Navigate to the proxies settings, and change to your proxy informations 3) Gradlew set system properties within your gradlew script by using one the environment variables DEFAULT_JVM_OPTS, JAVA_OPTS or GRADLE_OPTS. Changing to specific information. Thank you.","link":"/2019/07/19/2015-10-08-Install-Dependency-Under-Different-Languages/"},{"title":"OpenStack Nova 添加扩展API流程","text":"例子中涉及到SQLAlchemy 得相关操作，可以参考 上一随笔 Openstack 中规定，扩展openstack得api有两种方式 创建新的WSGI 资源 扩展原有得WSGI资源得控制器（我得理解是，接受到API请求后，具体得响应逻辑） 这两种方式中，都要求写一个新的模块来声明控制器类去处理请求和实现扩展。 在一个API模块中，可以有一个或多个得资源和扩展控制器。 根据osapi_compute_extension 得配置， ExtensionManager 由nova/api/openstack/compute/contrib/ 下的init.py 文件加载标准的或者新的扩展。 所以扩展的api统一写在nova/api/openstack/compute/contrib/ 目录下 如本例子中得 nova/api/openstack/compute/contrib/documents.py ##扩展API流程 实现控制器，完成对资源的基本操作，如增删改查和其他一些用户自定义的RESTful资源操作； 实现一个extensions.ExtensionDescriptor的子类， 并实现get_resources 或者 get_controller_extensions，来建立新的资源或扩展资源控制器（即改写原有的业务逻辑）。具体实现哪个方法这取决于是否要修改原有的RESTFul业务逻辑， 或者说两个功能都需要； 将控制器和扩展的资源类，写如新创建的的资源中； 规范是资源类是模块（问家名）首字母大写，这样做的目的是使nova.api.openstack.extensions.load_standard_extensions这个类能够是别该新资源，并予以加载； 当添加新的资源（extensions.ResourceExtension的子类）的时候，如果想要去除掉 {tenent_id} 链接，则需要编写自定义的路由访问规则（本例子中没有涉及） ###documents.py 实现 1 # vim: tabstop=4 shiftwidth=4 softtabstop=4 2 3 # Author: Yitao Jiang 4 # Email: willierjyt@gmail.com 5 6 import webob 7 from webob import exc 8 9 from nova import db 10 from nova import exception 11 from nova.api.openstack import extensions 12 authorize = extensions.extension_authorizer('compute', 'documents') 13 14 # 请求控制器， 即处理对资源的请求，予以响应 15 class DocumentsController(): 16 \"\"\"the Documents API Controller declearation\"\"\" 17 18 def index(self, req): 19 import pdb; pdb.set_trace() 20 documents = {} 21 context = req.environ['nova.context'] 22 authorize(context) 23 24 documents[\"key\"] = \"helloworld\" 25 return documents 26 27 def create(self, req): 28 documents = {} 29 context = req.environ['nova.context'] 30 authorize(context) 31 32 documents[\"key\"] = \"helloworld\" 33 return documents 34 35 def show(self, req, id): 37 documents = {} 38 context = req.environ['nova.context'] 39 authorize(context) 40 41 try: 42 document = db.document_get(context, id) 43 except : 44 raise webob.exc.HTTPNotFound(explanation=\"Document not found\") 45 46 documents[\"document\"] = document 47 return documents 48 49 def update(self, req): 50 documents = {} 51 context = req.environ['nova.context'] 52 authorize(context) 53 54 documents[\"key\"] = \"helloworld\" 55 return documents 56 57 def delete(self, req, id): 58 return webob.Response(status_int=202) 59 # 根据命名规范， 模块（python源文件）中的类名是模块名的首字母大写 60 class Documents(extensions.ExtensionDescriptor): 61 \"\"\"Documents ExtensionDescriptor implementation\"\"\" 62 63 name = \"documents\" 64 alias = \"os-documents\" 65 namespace = \"www.www.com\" 66 updated = \"2013-05-19T00:00:00+00:00\" 67 68 def get_resources(self): 69 \"\"\"register the new Documents Restful resource\"\"\" 70 71 resources = [extensions.ResourceExtension('os-documents', 72 DocumentsController()) 73 ] 74 75 return resources 在之后可以由以下几种方式来操作documents 资源 GET v2/{tenant_id}/ os-documents POST v2/{tenant_id}/ os-documents GET v2/{tenant_id}/ os-documents/{document_id} PUT v2/{tenant_id}/ os-documents/{document_id} DELETE v2/{tenant_id}/ os-documents/{document_id} ###扩展api时所修改的文件 1 nova/db/api.py 2 nova/db/sqlalchemy/api.py 3 nova/db/sqlalchemy/models.py nova/db/api.py 文件内容 ####数据操作API提供的方法，由Nova API 根据请求进行相应的操作， 由上面的请求控制器进行调用 1 def document_get(context, document_id): 2 \"\"\"Get a document or raise if it does not exist.\"\"\" 3 return IMPL.document_get(context, document_id) nova/db/sqlalchemy/api.py 文件内容 # 完成通过由SQLAlchemy操作数据库 1 @require_admin_context 2 def document_get(context, document_id): 3 4 session = get_session() 5 with session.begin(): 6 query = model_query(context, models.Document, session=session, read_deleted=\"yes\").filter_by(id=document_id) 7 8 result = query.first() 9 10 if not result or not query: 11 raise Exception() 12 13 return result SQLAlchemy 中定义的资源 nova/db/sqlalchemy/models.py（具体使用见上一 篇日志） 1 class Document(BASE, NovaBase): 2 \"\"\"Represents a document of customized extension.\"\"\" 3 4 __tablename__ = 'documents' 5 id = Column(Integer, primary_key=True) 6 title = Column(String(255)) 至此，添加添加新的nova API功能完成,重起api服务 调用 curl -v -X GET -H ‘X-Auth-Token: 8e5971b3ce0a4f039b895681e7c29361’ http://127.0.0.1:8774/v2/9b5903dd2d3443d8bb75ddffac27239a/extensions/os-documents | python -mjson.tool命令，可以看到返回，扩展添加成功 1 { 2 \"extension\": { 3 \"alias\": \"os-documents\", 4 \"description\": \"Documents ExtensionDescriptor implementation\", 5 \"links\": [], 6 \"name\": \"documents\", 7 \"namespace\": \"www.www.com\", 8 \"updated\": \"2013-05-19T00:00:00+00:00\" 9 } 10 } 数据库添加表documents， 结构如下 mysql> desc documents; +------------+--------------+------+-----+---------+----------------+ | Field | Type | Null | Key | Default | Extra | +------------+--------------+------+-----+---------+----------------+ | id | int(11) | NO | PRI | NULL | auto_increment | | title | varchar(255) | NO | | NULL | | | created_at | datetime | YES | | NULL | | | updated_at | datetime | YES | | NULL | | | deleted_at | datetime | YES | | NULL | | | deleted | int(11) | YES | | NULL | | +------------+--------------+------+-----+---------+----------------+ 6 rows in set (0.05 sec) mysql> select * from documents; +----+----------------+------------+------------+------------+---------+ | id | title | created_at | updated_at | deleted_at | deleted | +----+----------------+------------+------------+------------+---------+ | 1 | abcdefgiifeife | NULL | NULL | NULL | NULL | | 2 | 1qaz2wsx | NULL | NULL | NULL | NULL | +----+----------------+------------+------------+------------+---------+ 2 rows in set (0.03 sec) 1 curl -X GET -H 'X-Auth-Token: 8e5971b3ce0a4f039b895681e7c29361' http://127.0.0.1:8774/v2/9b5903dd2d3443d8bb75ddffac27239a/os-documents/1 | python -mjson.tool 2 返回结果 3 { 4 \"document\": { 5 \"created_at\": null, 6 \"deleted\": null, 7 \"deleted_at\": null, 8 \"id\": 1, 9 \"title\": \"abcdefgiifeife\", 10 \"updated_at\": null 11 } 12 } 至此新添加的资源，API 扩展成功， 可以在此基础上进行进一步的修改，完成需求 ###参考文档： Adding a Method to the OpenStack API","link":"/2019/07/19/2014-05-17-openstack-nova-adding-plugin/"},{"title":"cloud storage swift ceph","text":"###概述许多人对对象存储与像ISCSI、FC这类块存储混同，但是他们之间存在很大的差别。像fc这类的块存储只能提供块设备如系统中的sdb，对象存储只能通过特殊的客户端来访问，像百度网这一类 块存储对于云环境下是重要的一部分，主要用于存储虚拟机的镜像文件或者存储用户的文件，包括所有进行备份的数据，文件，图像等。对象存储的主要优势在于比企业级的商业存储更加的节约，并且保证规模扩展性和数据的冗余. ###Openstack Swift ###软件架构 OpenStack 对象存储(Swift)利用标准服务器组建集群，提供了冗余的，可扩展的分布式对象存储。分布式意味着数据的每一分份在集群中的存储节点上复制。复制的份数是可配置的但是对于生产环境最少是3份。 Swift 中的数据可以通过REST接口访问，根据需要可以对存储的数据进行相应的操作。每一个对象的访问路径包含三个元素：/account/container/objectobject存储了用户的实际的输入的数据 Accounts and containers提供了组织对象的方式，不允许嵌套的accounts 和 containers。 Swift 软件以组件的方式进行开发，包括account servers, container servers, 和object servers 除此之外，proxy server哟用于接受用户的api请求Account servers 对账户提供container listings的操作 Container servers 对于一个给定的容器提供object listings 的操作 Object servers返回数据本身 ###Rings 由于用户的数据在集群中分布，所以非常的有必要记录数据存放的位置。 Swift通过维护一个叫做_rings_的数据结构来完成数据的定位操作。Rings 在集群中的各个节点复制包括存储节点以及代理节点，这种方式使得swift避免了大部分存储系统依赖于集中单一的meta date服务器的弊端。由于ring文件存储的是集群中node的关系，而不是一个集中的数据map，所以在存储或者删除object是，不需要更新ring文件.这样有益于IO操作，极大程度的减少了访问的带来的不便 对于acount数据库、container数据库、和单独的object都有独立的rings文件，但是都已相同的方式进行工作。简单来说就是，对于一个给定的Account，container，或者object，ring返回的是它在物理存储节点上的位置，从技术的角度来说，这一过程包括一致性hash算法。在mirantis上有对ring工作原理的相关介绍 under-hood-of-swift-ring 和 openstack-swift-consistency-analysis. ###Proxy Server代理服务器暴露出public API并且接受对存储实体的请求。对于每一个请求，代理节点都会通过ring文件查找account，container以及object所在的物理位置。根据位置将请求转发.Objects 在代理节点和客户端间直接的以流的的方式进行传递，并且没有缓存 ###Object server这是一个简单的blob的存储服务器，可以存储数据、查询、删除数据。对象以二进制文件的方式在存储节点中，对象的metadata信息存储在xattrs（file’s extended attributes）上，这就要求存储object的节点必须支持xattrs 每一个object利用对象名的hash值以及操作的时间戳来进行存储路径的存储，最新的写操作会在记录中的最新位置（包括在分布式的场景下，创建的请求需要全局的同步时钟）以保证响应对象的最新的一个版本。删除操作也会记录为文件的一个版本，这就保证了已经删除的对象在集群间正确的复制，老的版本不会出现在用户的请求中 ###Container serverContainer 服务器用于查询object信息（listings）。并不知道具体的object的位置，但是对于一个给定的container可以查询到其包含的objects。listings 数据存储在sqlite3数据库中，并且向object一样，在集群间复制。象object总数、container的存储使用情况的统计值都会记录下来. 在所服务的节点上，会有一个特殊的进程swift-container-updater 不间断的想container数据库中填充数据，在一个container中的数据变化时，并对其数据库进行更新。通过ring来定位需要更新的account。 ###Account server与container server雷系，但是是处理container listings 的操作. ###Features and functions Replication: The number of object copies that can be configured manually. Object upload is a synchronous process: The proxy server returns a “201 Created” HTTP code only if more than half the replicas are written. Integration with OpenStack identity service (Keystone): Accounts are mapped to tenants. Auditing objects consistency: the md5 sum of an object on the file system compared to its metadata stored in xattrs. Container synchronization: This makes it possible to synchronize containers across multiple data centers. Handoff mechanism: It makes it possible to use an additional node to keep a replica in case of failure. If the object is more than 5 Gb, it has to be split: These parts are stored as separate objects and could be read simultaneously. ##Ceph Ceph is a distributed network storage with distributed metadata management and POSIX semantics. The Ceph object store can be accessed with a number of clients, including a dedicated cmdline tool, FUSE, and Amazon S3 clients (through a compatibility layer, called “S3 Gateway“). Ceph is highly modular – different sets of features are provided by different components which one can mix and match. Specifically, for object store accessible via s3 API it is enough to run three of them: object server, monitori ###Monitor serverceph-mon is a lightweight daemon that provides a consensus for distributed decision-making in a Ceph cluster. It also is the initial point of contact for new clients, and will hand out information about the topology of the cluster. Normally there would be three ceph-mon daemons, on three separate physical machines, isolated from each other; for example, in different racks or rows. ###Object serverThe actual data put onto Ceph is stored on top of a cluster storage engine called RADOS, deployed on a set of storage nodes. ceph-osd is the storage daemon that runs on every storage node (object server) in the Ceph cluster. ceph-osd contacts ceph-mon for cluster membership. Its main goal is to service object read/write/etc. requests from clients, It also peers with other ceph-osds for data replication. The data model is fairly simple at this level. There are multiple named pools, and within each pool there are named objects, in a flat namespace (no directories). Each object has both data and metadata. The data for an object is a single, potentially big, series of bytes. The metadata is an unordered set of key-value pairs. Ceph filesystem uses metadata to store file owner, etc. Underneath, ceph-osd stores the data on a local filesystem. We recommend Btrfs, but any POSIX filesystem that has extended attributes should work. ###CRUSH algorithmWhile Swift uses rings (md5 hash range mapping against sets of storage nodes) for consistent data distribution and lookup, Ceph uses an algorithm called CRUSH for this. In short, CRUSH is an algorithm that can calculate the physical location of data in Ceph, given the object name, cluster map and CRUSH rules as input. CRUSH describes the storage cluster in a hierarchy that reflects its physical organization, and thus can also ensure proper data replication on top of physical hardware. Also CRUSH allows data placement to be controlled by policy, which allows CRUSH to adapt to changes in the cluster membership. ###Rados Gatewayradosgw is a FastCGI service that provides a RESTful HTTP API to store objects and metadata on the Ceph cluster. ###Features and functions Partial or complete reads and writes Snapshots Atomic transactions with features like append, truncate, and clone range Object level key-value mappings Object replicas management Aggregation of objects (series of objects) into a group, and mapping the group to a series of OSDs Authentication with shared secret keys: Both the client and the monitor cluster- have a copy of the client’s secret key Compatibility with S3/Swift API ###Feature summary Swift Ceph Replication Yes Yes Max. obj.size 5gb(bigger objects segmented) Unlimited Multi DCinstallation Yes (replication on the container level only,but a blueprint proposed for full inter dc replication) No (demands asynchronous eventual consistency replication, which Ceph does not yet support) Integration/w Opentsack Yes Partial(lack of Keystone support) Replicasmanagement No Yes Writingalgorithm Synchronous Synchronous Amazon S3 compatible API Yes Yes Data placement method Ring (static mapping structure) CRUSH (algorithm) ###参考文章 http://www.mirantis.com/blog/object-storage-openstack-cloud-swift-ceph","link":"/2019/07/19/2014-06-03-cloud-storage-swift-ceph/"},{"title":"Cloudstack Debugging SystemVm agents","text":"##Cloudstack Debug a live agentlogin into ssvm, either console proxy or ssh(port 3922)kill all the processes named as(run.sh/_run.sh, and java) cd /usr/local/cloud/systemvm add parameters “-Xdebug -Xrunjdwp:transport=dt_socket,server=y,suspend=n,address=8787” after “java “ in the last line of _run.sh ./run.sh, the java agent will start, with debug port 8787 is listened on. allow port 8787 in ssvm, “iptables -I INPUT -i eth1 -p tcp -m state –state NEW -m tcp –dport 8787 -j ACCEPT”, either eth1 or eth2 is ok. Log in into ssvm - Log into the hypervisor and then type the following command “ssh -i /opt/xensource/bin/id_rsa –p 3922 root@privateIP_or_LinkLocalIpofSSVM”, or “ssh -i /root/.ssh/id_rsa.cloud -p 3922 root@LinkLocal” on XenServer. Private ip in case of vmware and linklocal in case Xenserver. Vmware do not have link local ip. SSVM can be accessed from Management server using private ip address .Ex: ssh -i /var/cloudstack/management/.ssh/id_rsa -p 3922 root@ Log in into ssvm - Log into the hypervisor and then type the following command “ssh -i /opt/xensource/bin/id_rsa –p 3922 root@privateIP_or_LinkLocalIpofSSVM”, or “ssh -i /root/.ssh/id_rsa.cloud -p 3922 root@LinkLocal” on XenServer. Private ip in case of vmware and linklocal in case Xenserver. Vmware do not have link local ip. SSVM can be accessed from Management server using private ip address .Ex: ssh -i /var/cloudstack/management/.ssh/id_rsa -p 3922 root@ SSVM health check - Run the following script inside ssvm /usr/local/cloud/systemvm/ssvm-check.sh It checks for 1. connectivity with DNS server 2. resolving of domain names 3. status of secondary storage 4. ability to write to secondary storage 5. connectivity with management server at port 8250 and status of java process. NOTE - If you dont find the health check script then go to #9. Most probably your ssvm didnt get patched right. Template not ready / not available when creating an instance - Many a times the SSVM is running but still the templates do not show as ready or to say templates are not available when creating an instance. Run the health check script above and diagnose. The most probable reason reason is that the agent running on SSVM hasn’t been able to connect with MS which could also be validated by checking the host table in DB. select * from host where type like ‘SecondaryStorageVM’. If the status shows as Alert then definitely that is the reason. There could be a number of reasons for the agent not being able to connect with MS. Below three could be one of them. Check whether port 8250 is open on MS and there is no firewall rule. This is the port on which the agent and MS communication happens. Check whether the SSVM is trying to connect to the right ip of MS. If it is incorrect it could be due to the wrong ip being set in the global settings (configuration table) for ‘host’ in MS. Change that, restart MS and SSVM and see if it solves the issue. Check the agent status on SSVM- See if the agent is running by typing “service cloud status” in SSVM. Try to run it and see if that’s successful or changes the alert status. To check the state of templates whether is has downloaded or there is an error - Log into DB and check table template_host_ref and observe the download_state and error_string. Templates stuck in download in progress - Either stop and then start the SSVM. Or, run service cloud restart on the SSVM. You can also restart MS. This would trigger template sync which essentially will try and resume such stuck templates or redo the download of erred out templates. Whenever there is a handshake between MS and the agent running on the SSVM there is a template sync which syncs the template status on the MS DB and the template’s physical Location and triggers the download if its not complete or retries in case there was some error. (This handshake happens on ssvm re/start, agent re/start and MS re/start)Connection refused as the status for the template - Check whether the config parameter “secstorage.allowed.internal.sites” has been set to allow the internal n/w URL’s. Retrying the download of templates - Refer #5 above ###no route to hostThis error often implies your firewall blocks the traffic, check iptable rules in SSVM then host then physical firewall. ###SSVM agent not runningYou see error something like below. Most probably your systemvm didnt get patched with the agent specific code. This patching happens through the ISO - something like systemvm***.iso. Check the size and location of the iso and whether you are not using the old version iso. For XS its on the host so grep for it and for vmware its on secondary storage. Do also check that if its vmware that you built your ssvm using noredist flag for mvn command.2013-12-20 13:35:12,954 DEBUG [cloud.utils.ProcessUtil] (main:null) Execution is successful.2013-12-20 13:35:12,960 ERROR [cloud.agent.AgentShell] (main:null) Unable to start agent: Resource class not found: com.cloud.storage.resource.PremiumSecondaryStorageResource due to: java.lang.ClassNotFoundException: com.cloud.storage.resource.PremiumSecondaryStorageResourceDont see any health check script on SSVM or the agent running - The issue for sure is as in #9 above. For vmware setup I saw that because the systemvm.iso size wasnt right.SSVM Logs - /var/log/cloud/cloud.log*ERROR: Java process not running. Try restarting the SSVM - *It looks like the scripts/java binaries have not been copied into the SSVM ? See this thread http://markmail.org/thread/niu2qwsdydkuh2f for how it is supposed to work (response from Alex) ###Available secondary storage space is lowshows only ~2 gb. Generally this is because the secondary storage is not mounted correctly. Run the step 2 above to verify that. One of the reasons could be “It’s due to IP access-list settings which was turned on by default on NAS4Free. Have allowed the SSVM’s IP address to mount to the NAS and it’s now working fine.”SSVM nics - SSVM basically has four nics, they are: eth0: link local nic used for ssh login from host eth1: private nic used as management interface between mgmt server and SSVM eth2: public nic used as interface that can reach outside internet eth3: storage nic used as interface to access secondary storage share like NFS CloudStack sets route for each nic, however, the most important route ‘default’ is set to public nic which is eth2. That means a healthy SSVM should have default route like(by command ‘ip route’):default via public_gateway_ip_address dev eth2 this also implies communication between SSVMs happen thru public nic even both SSVMs are in the same private subnet. SSVM templates physical location - find the mount point by typing command “mount” . Go to the directory and under template/tmpl you will find all the templates. SSVM Apache server - For 2.2 onwards the system vms are debian based. Type “service apache2 status” to find the status. Apache root is at /www/html/Run script of java process /usr/local/cloud/systemvm/run.shIncreasing log level - 1) Edit the file /usr/local/cloud/systemvm/conf/log4j-cloud.xml 2) For the log file cloud.log change the threshold to info: to 3) Change com.cloud to INFO: If you’re not getting sufficient logging, you can also try setting it to DEBUG. Multiple secondary storages feature has been added since some time now. The private templates are copied to one of the secondary storages and public to all of them for higher availability.All the public templates will be replicated to all the secondary storage for redundancy but private templates and uploaded volumes would be kept in one of the randomly chosen secondary storage. Snapshots are randomly copied to one of the secondary storage (the chain of incremental snapshots are kept on the same secondary storage.) Currently these algorithms are hardcoded and there is no way to tweak it. In case you need flexibility please open an enhancement for the same. During template sync the consistency is again checked and download triggered for templates keeping in mind the algorithm above.SSVM and CPVM do not have agents running AND SSVM health check runs fine. cloud.log on SSVM/CPVM keeps showing the following message:2014-06-16 08:08:01,108 INFO [utils.nio.NioClient] (Agent-Selector:null) Connecting to 10.102.192.247:82502014-06-16 08:08:01,872 ERROR [utils.nio.NioConnection] (Agent-Selector:null) Unable to initialize the threads.java.io.IOException: SSL: Fail to init SSL! java.io.IOException: Connection closed with -1 on reading size.at com.cloud.utils.nio.NioClient.init(NioClient.java:84)at com.cloud.utils.nio.NioConnection.run(NioConnection.java:108)at java.lang.Thread.run(Thread.java:701) ###Solution : rm ./client/target/cloud-client-ui-4.3.0.0/WEB-INF/classes/cloudmanagementserver.keystore ./client/target/conf/cloudmanagementserver.keystore ./client/target/generated-webapp/WEB-INF/classes/cloudmanagementserver.keystore remove root entry from cloud.keystore; remove ssl.keystore from cloud.configuration where description like ‘%key%’; restart MS agent in ssvm Download Complete 100% but getting error like this Failed post download script: /usr/sbin/vhd-utilvhd tool check /mnt/SecStorage/33e2e9f5/template/tmpl/345/447/dnld1469110483936142751tmp_ failed - Many reasons for this but amongst them are wrong OS selection, vhd corruption. Test this in the lab by copying the template to one of the hosts then on that host run vhd-util check -n filename.vhd vhd-util scan filename.vhd SSVM RAM - Set the param secstorage.vm.ram.size to in change the ram size of the vm. Default in the code is 256. For each secondary storage there is a corresponding row created in the host table. HTTP Server returned 403 (expected 200 OK) - For copy templates. Try to see the first log for this template initiation ? It should be logged with DownloadCommand and should have the url of the source ssvm’s template. Then you can try going to the destination SSVM and try downloading that url. See what issues you get. I would also check the iptable rules to see if the destination ssvm is blocked from accessing the source ssvm and also if there is any .htaccess file in the apache directories forbidding the download of template One of the problems as was as follows.*The problem is that we’re using basic networking &amp; have the private network setup with the same gateway &amp; subnet as the public network. When the storage VM comes up the public network gets setup first but then when the private network comes up on eth2 it clobbers the gateway &amp; sets it to the eth2 interface. So when the copy is initiated between the storage VMs it happens across the private network but the /var/www/html/copy/.htaccess file only allows the public IP of the other SSVM, thus the 403 errors.","link":"/2019/07/19/2014-09-03-cloudstack-debugging-systemvm-agents/"},{"title":"Using Stackedit for Github Markdown","text":". Welcome to StackEdit!Hey! I’m your first Markdown document in StackEdit[^stackedit]. Don’t delete me, I’m very helpful! I can be recovered anyway in the Utils tab of the Settings dialog. DocumentsStackEdit stores your documents in your browser, which means all your documents are automatically saved locally and are accessible offline! Note: StackEdit is accessible offline after the application has been loaded for the first time. Your local documents are not shared between different browsers or computers. Clearing your browser’s data may delete all your local documents! Make sure your documents are synchronized with Google Drive or Dropbox (check out the Synchronization section). Create a documentThe document panel is accessible using the button in the navigation bar. You can create a new document by clicking New document in the document panel. Switch to another documentAll your local documents are listed in the document panel. You can switch from one to another by clicking a document in the list or you can toggle documents using Ctrl+[ and Ctrl+]. Rename a documentYou can rename the current document by clicking the document title in the navigation bar. Delete a documentYou can delete the current document by clicking Delete document in the document panel. Export a documentYou can save the current document to a file by clicking Export to disk from the menu panel. Tip: Check out the Publish a document section for a description of the different output formats. SynchronizationStackEdit can be combined with Google Drive and Dropbox to have your documents saved in the Cloud. The synchronization mechanism takes care of uploading your modifications or downloading the latest version of your documents. Note: Full access to Google Drive or Dropbox is required to be able to import any document in StackEdit. Permission restrictions can be configured in the settings. Imported documents are downloaded in your browser and are not transmitted to a server. If you experience problems saving your documents on Google Drive, check and optionally disable browser extensions, such as Disconnect. Open a documentYou can open a document from Google Drive or the Dropbox by opening the Synchronize sub-menu and by clicking Open from…. Once opened, any modification in your document will be automatically synchronized with the file in your Google Drive / Dropbox account. Save a documentYou can save any document by opening the Synchronize sub-menu and by clicking Save on…. Even if your document is already synchronized with Google Drive or Dropbox, you can export it to a another location. StackEdit can synchronize one document with multiple locations and accounts. Synchronize a documentOnce your document is linked to a Google Drive or a Dropbox file, StackEdit will periodically (every 3 minutes) synchronize it by downloading/uploading any modification. A merge will be performed if necessary and conflicts will be detected. If you just have modified your document and you want to force the synchronization, click the button in the navigation bar. Note: The button is disabled when you have no document to synchronize. Manage document synchronizationSince one document can be synchronized with multiple locations, you can list and manage synchronized locations by clicking Manage synchronization in the Synchronize sub-menu. This will let you remove synchronization locations that are associated to your document. Note: If you delete the file from Google Drive or from Dropbox, the document will no longer be synchronized with that location. PublicationOnce you are happy with your document, you can publish it on different websites directly from StackEdit. As for now, StackEdit can publish on Blogger, Dropbox, Gist, GitHub, Google Drive, Tumblr, WordPress and on any SSH server. Publish a documentYou can publish your document by opening the Publish sub-menu and by choosing a website. In the dialog box, you can choose the publication format: Markdown, to publish the Markdown text on a website that can interpret it (GitHub for instance), HTML, to publish the document converted into HTML (on a blog for example), Template, to have a full control of the output. Note: The default template is a simple webpage wrapping your document in HTML format. You can customize it in the Advanced tab of the Settings dialog. Update a publicationAfter publishing, StackEdit will keep your document linked to that publication which makes it easy for you to update it. Once you have modified your document and you want to update your publication, click on the button in the navigation bar. Note: The button is disabled when your document has not been published yet. Manage document publicationSince one document can be published on multiple locations, you can list and manage publish locations by clicking Manage publication in the menu panel. This will let you remove publication locations that are associated to your document. Note: If the file has been removed from the website or the blog, the document will no longer be published on that location. Markdown ExtraStackEdit supports Markdown Extra, which extends Markdown syntax with some nice features. Tip: You can disable any Markdown Extra feature in the Extensions tab of the Settings dialog. Note: You can find more information about Markdown syntax here and Markdown Extra extension here. TablesMarkdown Extra has a special syntax for tables: Item Value Computer $1600 Phone $12 Pipe $1 You can specify column alignment with one or two colons: Item Value Qty Computer $1600 5 Phone $12 12 Pipe $1 234 Definition ListsMarkdown Extra has a special syntax for definition lists too: Term 1Term 2: Definition ADefinition BTerm 3 : Definition C : Definition D &gt; part of definition DFenced code blocksGitHub’s fenced code blocks are also supported with Highlight.js syntax highlighting: 12// Foovar bar = 0; Tip: To use Prettify instead of Highlight.js, just configure the Markdown Extra extension in the Settings dialog. Note: You can find more information: about Prettify syntax highlighting here, about Highlight.js syntax highlighting here. FootnotesYou can create footnotes like this[^footnote]. [^footnote]: Here is the text of the footnote. SmartyPantsSmartyPants converts ASCII punctuation characters into “smart” typographic punctuation HTML entities. For example: ASCII HTML Single backticks &#39;Isn&#39;t this fun?&#39; ‘Isn’t this fun?’ Quotes &quot;Isn&#39;t this fun?&quot; “Isn’t this fun?” Dashes -- is en-dash, --- is em-dash – is en-dash, — is em-dash Table of contentsYou can insert a table of contents using the marker [TOC]: [TOC] MathJaxYou can render LaTeX mathematical expressions using MathJax, as on math.stackexchange.com: The Gamma function satisfying $\\Gamma(n) = (n-1)!\\quad\\forall n\\in\\mathbb N$ is via the Euler integral $$\\Gamma(z) = \\int_0^\\infty t^{z-1}e^{-t}dt,.$$ Tip: To make sure mathematical expressions are rendered properly on your website, include MathJax into your template: 1&lt;script type=&quot;text/javascript&quot; src=&quot;https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML&quot;&gt;&lt;/script&gt; Note: You can find more information about LaTeX mathematical expressions here. UML diagramsYou can also render sequence diagrams like this: 123Alice-&gt;Bob: Hello Bob, how are you?Note right of Bob: Bob thinksBob--&gt;Alice: I am good thanks! And flow charts like this: 12345678st=&gt;start: Starte=&gt;endop=&gt;operation: My Operationcond=&gt;condition: Yes or No?st-&gt;op-&gt;condcond(yes)-&gt;econd(no)-&gt;op Note: You can find more information: about Sequence diagrams syntax here, about Flow charts syntax here. Support StackEdit [^stackedit]: StackEdit is a full-featured, open-source Markdown editor based on PageDown, the Markdown library used by Stack Overflow and the other Stack Exchange sites.","link":"/2019/07/19/2015-07-07-using-stackedit-for-github-markdown/"}],"tags":[{"name":"Cloudstack","slug":"Cloudstack","link":"/tags/Cloudstack/"},{"name":"Debug","slug":"Debug","link":"/tags/Debug/"},{"name":"e-commerce","slug":"e-commerce","link":"/tags/e-commerce/"},{"name":"django","slug":"django","link":"/tags/django/"},{"name":"python","slug":"python","link":"/tags/python/"},{"name":"posgres","slug":"posgres","link":"/tags/posgres/"},{"name":"4.2.1","slug":"4-2-1","link":"/tags/4-2-1/"},{"name":"Operator","slug":"Operator","link":"/tags/Operator/"},{"name":"Django","slug":"Django","link":"/tags/Django/"},{"name":"cloudstack 4.2.1","slug":"cloudstack-4-2-1","link":"/tags/cloudstack-4-2-1/"},{"name":"Workflow","slug":"Workflow","link":"/tags/Workflow/"},{"name":"Hack","slug":"Hack","link":"/tags/Hack/"},{"name":"Python","slug":"Python","link":"/tags/Python/"},{"name":"neutron","slug":"neutron","link":"/tags/neutron/"},{"name":"Xenserver","slug":"Xenserver","link":"/tags/Xenserver/"},{"name":"VDI","slug":"VDI","link":"/tags/VDI/"},{"name":"Havana","slug":"Havana","link":"/tags/Havana/"},{"name":"libvirt","slug":"libvirt","link":"/tags/libvirt/"},{"name":"Linux","slug":"Linux","link":"/tags/Linux/"},{"name":"Virsh","slug":"Virsh","link":"/tags/Virsh/"},{"name":"Git","slug":"Git","link":"/tags/Git/"},{"name":"OpenVAS","slug":"OpenVAS","link":"/tags/OpenVAS/"},{"name":"Network","slug":"Network","link":"/tags/Network/"},{"name":"Security","slug":"Security","link":"/tags/Security/"},{"name":"mysql","slug":"mysql","link":"/tags/mysql/"},{"name":"Cloudmonkey","slug":"Cloudmonkey","link":"/tags/Cloudmonkey/"},{"name":"cloudstack","slug":"cloudstack","link":"/tags/cloudstack/"},{"name":"trouble-shooting","slug":"trouble-shooting","link":"/tags/trouble-shooting/"},{"name":"Events","slug":"Events","link":"/tags/Events/"},{"name":"powerdns","slug":"powerdns","link":"/tags/powerdns/"},{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"Sysadmin","slug":"Sysadmin","link":"/tags/Sysadmin/"},{"name":"Docker","slug":"Docker","link":"/tags/Docker/"},{"name":"Installation","slug":"Installation","link":"/tags/Installation/"},{"name":"Proxy","slug":"Proxy","link":"/tags/Proxy/"},{"name":"Nova","slug":"Nova","link":"/tags/Nova/"},{"name":"Github","slug":"Github","link":"/tags/Github/"}],"categories":[{"name":"Cloudstack","slug":"Cloudstack","link":"/categories/Cloudstack/"},{"name":"commerce","slug":"commerce","link":"/categories/commerce/"},{"name":"cloudstack","slug":"cloudstack","link":"/categories/cloudstack/"},{"name":"Python","slug":"Python","link":"/categories/Python/"},{"name":"openstack","slug":"openstack","link":"/categories/openstack/"},{"name":"Xenserver","slug":"Xenserver","link":"/categories/Xenserver/"},{"name":"Libvirt","slug":"Libvirt","link":"/categories/Libvirt/"},{"name":"Git","slug":"Git","link":"/categories/Git/"},{"name":"Linux","slug":"Linux","link":"/categories/Linux/"},{"name":"OpenVAS","slug":"OpenVAS","link":"/categories/OpenVAS/"},{"name":"Mysql","slug":"Mysql","link":"/categories/Mysql/"},{"name":"sysadmin","slug":"sysadmin","link":"/categories/sysadmin/"},{"name":"Sysadmin","slug":"Sysadmin","link":"/categories/Sysadmin/"},{"name":"Docker","slug":"Docker","link":"/categories/Docker/"},{"name":"linux","slug":"linux","link":"/categories/linux/"},{"name":"Developting","slug":"Developting","link":"/categories/Developting/"},{"name":"Storage","slug":"Storage","link":"/categories/Storage/"},{"name":"editor","slug":"editor","link":"/categories/editor/"}]}